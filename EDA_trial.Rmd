---
title: "EDA_trial"
author: "The BOYZ"
date: "2024-04-05"
output: pdf_document
---
```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
```

```{r}
pittsburgh_pollution_data <- read_csv("Data/cleaned_pollution_data.csv")
```


```{r}
ppd_lawrenceville <- pittsburgh_pollution_data %>%
  filter(site == "Lawrenceville" & is_valid == "TRUE")
```


```{r}
ppd_lawrenceville_SO2 <- ppd_lawrenceville %>%
  filter(parameter == "SO2") %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))

ggplot(ppd_lawrenceville_SO2, aes(x = datetime_est, y = report_value)) +
  geom_point(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()


```

```{r}
ppd_lawrenceville_SO2_2019 <- ppd_lawrenceville_SO2 %>%
  filter(year(datetime_est) == 2019)

# Convert datetime_est to Date format (removing the time component)
ppd_lawrenceville_SO2_2019 <- ppd_lawrenceville_SO2_2019 %>%
  mutate(date = as.Date(datetime_est))

# Calculate the mean report_value for each day
daily_means <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(mean_report_value = mean(report_value))

# Calculate the median report_value for each day
daily_medians <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(median_report_value = median(report_value))

# Plot the mean report_value over each day in 2019
ggplot(daily_means, aes(x = date, y = mean_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Mean Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot the median report_value over each day in 2019
ggplot(daily_medians, aes(x = date, y = median_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Median Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Calculate the abs. val mean report_value for each day
abs_daily_means <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(abs_mean_report_value = mean(abs(report_value)))

# Plot the mean report_value over each day in 2019
ggplot(abs_daily_means, aes(x = date, y = abs_mean_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Mean Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ppd_lawrenceville_vars <- ppd_lawrenceville %>%
  filter(parameter %in% c("NO", "SO2", "CO", "PM10B", "PM25B", "OZONE", "INT_T", "OUT_T", "SONICWS", "SONICWD", "OUT_RH", "BP", "Peak Wind Gust", "RAINFALL")) %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))

head(ppd_lawrenceville_vars)

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "NO"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "SO2"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "CO"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "PM10B"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "PM25B"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

```

```{r}
ppd_lawrenceville_PM10B <- ppd_lawrenceville_vars %>% 
  filter(parameter == "PM10B") %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))
ppd_lawrenceville_PM10B$datetime_est <- as.POSIXct(ppd_lawrenceville_PM10B$datetime_est)

# Create a sequence of datetime values starting from "2016-01-01 00:00:00" and incrementing by one hour
datetime_seq <- seq(from = as.POSIXct("2016-01-01 00:00:00"), 
                    by = "1 hour", 
                    length.out = nrow(ppd_lawrenceville_PM10B))

# Create a time series object using the report_value column and the datetime sequence
PM10B_ts <- ts(ppd_lawrenceville_PM10B$report_value, start = c(2016, 1), frequency = 365.25*24)

plot(PM10B_ts)
```

```{r}
library(forecast)
library(ggplot2)
library(vars)
```

```{r}
#long to wide, only for the variables of interest (parameter and report value)--no need for anything else
ppd_lawrenceville_vars_wide <- ppd_lawrenceville_vars %>%
  spread(parameter, report_value)

#remove unnecessary columns
ppd_lawrenceville_vars_wide <- subset(ppd_lawrenceville_vars_wide, select = -c(is_valid, unit, unit_description, highest_flag, aqs_parameter_category, hour, site))


#collapse the data into a single row for each datetime_est
ppd_lawrenceville_vars_wide <- ppd_lawrenceville_vars_wide %>%
  group_by(datetime_est) %>%
  summarise_all(mean, na.rm = TRUE)

#fill na with zero
ppd_lawrenceville_vars_wide[is.na(ppd_lawrenceville_vars_wide)] <- 0
```

```{r}
#split the data into pollutants and environmental variables
pollutants <- ppd_lawrenceville_vars_wide[, c("datetime_est", "NO", "SO2", "CO", "PM10B", "PM25B", "OZONE")]
environmentalvariables <- ppd_lawrenceville_vars_wide[, c("datetime_est", "BP", "INT_T", "OUT_RH", "OUT_T", 
                                                          "Peak Wind Gust", "RAINFALL", "SONICWD", "SONICWS")]
```


```{r}
#add the inversion data to the environmental variables
inversion_data <- read.csv("inversionseries.csv")

#keep only unique observations, so must de-dupe the data
inversion_data <- inversion_data[, c("time", "inversion")]
inversion_data <- inversion_data[!duplicated(inversion_data), ]

#expand the series to include all dates, set NA to False
inversion_data$time <- as.POSIXct(inversion_data$time)
inversion_data <- padr::pad(inversion_data, interval = "hour")
#replace the NA values with the value of the previous non-NA value
inversion_data$inversion <- zoo::na.locf(inversion_data$inversion)

#merge the inversion data with the environmental variables
environmentalvariables <- merge(environmentalvariables, inversion_data, by.x = "datetime_est", by.y = "time", all.x = TRUE)
```

```{r}
#merge the two datasets together, then split them back out
ppd_lawrenceville_vars_wide <- merge(pollutants, environmentalvariables, by = "datetime_est", all = TRUE)

pollutants <- ppd_lawrenceville_vars_wide[, c("NO", "SO2", "CO", "PM10B", "PM25B", "OZONE")]
environmentalvariables <- ppd_lawrenceville_vars_wide[, c("BP", "INT_T", "OUT_RH", "OUT_T", 
                                                          "Peak Wind Gust", "RAINFALL", "SONICWD", "SONICWS", "inversion")]
```

```{r}
#set the na values to false
environmentalvariables$inversion[is.na(environmentalvariables$inversion)] <- "False"
```

```{r}
#convert character to true boolean
environmentalvariables$inversion <- as.logical(environmentalvariables$inversion)
```

```{r}
rm(pittsburgh_pollution_data, ppd_lawrenceville, ppd_lawrenceville_vars, ppd_lawrenceville_vars_wide, inversion_data, daily_means, daily_medians)
rm(abs_daily_means, ppd_lawrenceville_PM10B, ppd_lawrenceville_SO2, ppd_lawrenceville_SO2_2019)
```

```{r}
rm(PM10B_ts, datetime_seq)
rm(train)
```



```{r}
#seasonal differencing
for(i in 1:ncol(pollutants)){
  pollutants[,i] <- pollutants[, i] - lag(pollutants[, i], 24*365)
}
#fill to front with the first non-na value
pollutants <- na.locf(pollutants, fromLast = T)
```

```{r}
#get the row numbers of the missing values
#missing_values1 <- which(is.na(pollutants), arr.ind = TRUE)
#missing_values2 <- which(is.na(environmentalvariables), arr.ind = TRUE)
#drop the missing values from environmentalvariables and pollutants
#environmentalvariables <- environmentalvariables[-missing_values1[,1], ]
#pollutants <- pollutants[-missing_values2[,1], ]
```


```{r}
#this line of code takes a day to run.
#model_select <- VARselect(y=pollutants, lag.max = 50, type = "trend", exogen = environmentalvariables)
```


```{r}
# Fit the VAR model (lag choices are 29, 45, 70)
var_1 <- VAR(pollutants, p = 29, exogen = environmentalvariables)
var_2 <- VAR(pollutants, p = 45, exogen = environmentalvariables)
var_3 <- VAR(pollutants, p = 70, exogen = environmentalvariables)

```


```{r}
#evaluate the model
coef(var_1)
```

```{r}
coef(var_2)
```

```{r}
coef(var_3)
```



