---
title: "EDA_trial"
author: "The BOYZ"
date: "2024-04-05"
output: pdf_document
---
```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
```

```{r}
pittsburgh_pollution_data <- read_csv("Data/cleaned_pollution_data.csv")
```


```{r}
ppd_lawrenceville <- pittsburgh_pollution_data %>%
  filter(site == "Lawrenceville" & is_valid == "TRUE")
```


```{r}
ppd_lawrenceville_SO2 <- ppd_lawrenceville %>%
  filter(parameter == "SO2") %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))

ggplot(ppd_lawrenceville_SO2, aes(x = datetime_est, y = report_value)) +
  geom_point(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()


```

```{r}
ppd_lawrenceville_SO2_2019 <- ppd_lawrenceville_SO2 %>%
  filter(year(datetime_est) == 2019)

# Convert datetime_est to Date format (removing the time component)
ppd_lawrenceville_SO2_2019 <- ppd_lawrenceville_SO2_2019 %>%
  mutate(date = as.Date(datetime_est))

# Calculate the mean report_value for each day
daily_means <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(mean_report_value = mean(report_value))

# Calculate the median report_value for each day
daily_medians <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(median_report_value = median(report_value))

# Plot the mean report_value over each day in 2019
ggplot(daily_means, aes(x = date, y = mean_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Mean Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot the median report_value over each day in 2019
ggplot(daily_medians, aes(x = date, y = median_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Median Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Calculate the abs. val mean report_value for each day
abs_daily_means <- ppd_lawrenceville_SO2_2019 %>%
  group_by(date) %>%
  summarise(abs_mean_report_value = mean(abs(report_value)))

# Plot the mean report_value over each day in 2019
ggplot(abs_daily_means, aes(x = date, y = abs_mean_report_value)) +
  geom_line(color = "blue") +    # Line plot
  geom_point(color = "red", size = 2) +   # Points
  labs(x = "Date", y = "Mean Report Value", title = "Mean Report Value Over Time in 2019") +
  theme_minimal() +    # Minimal theme
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ppd_lawrenceville_vars <- ppd_lawrenceville %>%
  filter(parameter %in% c("NO", "SO2", "CO", "PM10B", "PM25B", "INT_T", "OUT_T", "SONICWS", "SONICWD", "OUT_RH", "BP", "Peak Wind Gust", "RAINFALL")) %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))

head(ppd_lawrenceville_vars)

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "NO"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "SO2"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "CO"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "PM10B"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

ggplot(ppd_lawrenceville_vars %>% filter(parameter == "PM25B"), aes(x = datetime_est, y = report_value)) +
  geom_line(color = "red", size = 1) +   # Points
  labs(x = "Hour of the Day", y = "Report Value", title = "Time Series Plot of Report Value") +
  theme_minimal()

```

```{r}
ppd_lawrenceville_PM10B <- ppd_lawrenceville_vars %>% 
  filter(parameter == "PM10B") %>%
  mutate(hour = as.numeric(format(datetime_est, "%H")))
ppd_lawrenceville_PM10B$datetime_est <- as.POSIXct(ppd_lawrenceville_PM10B$datetime_est)

# Create a sequence of datetime values starting from "2016-01-01 00:00:00" and incrementing by one hour
datetime_seq <- seq(from = as.POSIXct("2016-01-01 00:00:00"), 
                    by = "1 hour", 
                    length.out = nrow(ppd_lawrenceville_PM10B))

# Create a time series object using the report_value column and the datetime sequence
PM10B_ts <- ts(ppd_lawrenceville_PM10B$report_value, start = c(2016, 1), frequency = 365.25*24)

plot(PM10B_ts)
```

```{r}
library(forecast)
library(ggplot2)
library(vars)
```

```{r}
#long to wide, only for the variables of interest (parameter and report value)--no need for anything else
ppd_lawrenceville_vars_wide <- ppd_lawrenceville_vars %>%
  spread(parameter, report_value)

#remove unnecessary columns
ppd_lawrenceville_vars_wide <- subset(ppd_lawrenceville_vars_wide, select = -c(is_valid, unit, unit_description, highest_flag, aqs_parameter_category, hour, site))


#collapse the data into a single row for each datetime_est
ppd_lawrenceville_vars_wide <- ppd_lawrenceville_vars_wide %>%
  group_by(datetime_est) %>%
  summarise_all(mean, na.rm = TRUE)

#fill na with zero
ppd_lawrenceville_vars_wide[is.na(ppd_lawrenceville_vars_wide)] <- 0
```

```{r}
#split the data into pollutants and environmental variables
pollutants <- ppd_lawrenceville_vars_wide[, c("NO", "SO2", "CO", "PM10B", "PM25B")]
environmentalvariables <- ppd_lawrenceville_vars_wide[, c("datetime_est", "BP", "INT_T", "OUT_RH", "OUT_T", 
                                                          "Peak Wind Gust", "RAINFALL", "SONICWD", "SONICWS")]
```


```{r}
#add the inversion data to the environmental variables
inversion_data <- read.csv("inversionseries.csv")

#keep only unique observations, so must de-dupe the data
inversion_data <- inversion_data[, c("time", "inversion")]
inversion_data <- inversion_data[!duplicated(inversion_data), ]

#expand the series to include all dates, set NA to False
inversion_data$time <- as.POSIXct(inversion_data$time)
inversion_data <- padr::pad(inversion_data, interval = "hour")
#replace the NA values with the value of the previous non-NA value
inversion_data$inversion <- zoo::na.locf(inversion_data$inversion)

#merge the inversion data with the environmental variables
environmentalvariables <- merge(environmentalvariables, inversion_data, by.x = "datetime_est", by.y = "time", all.x = TRUE)
#drop the datetime_est and time columns, we won't need them
environmentalvariables <- environmentalvariables[, 2:10]
```


```{r}
#this line of code takes a day to run.
model_select <- VARselect(y=pollutants, lag.max = 70, season = 9*24*30, type = "trend", exogen = environmentalvariables)
```


```{r}
# Fit the VAR model (lag choices are 29, 45, 70)
var_1 <- VAR(pollutants, p = 29, type = "trend", season = 9*24*30, exogen = environmentalvariables)
var_2 <- VAR(pollutants, p = 45, type = "trend", season = 9*24*30, exogen = environmentalvariables)
var_3 <- VAR(pollutants, p = 70, type = "trend", season = 9*24*30, exogen = environmentalvariables)

```


